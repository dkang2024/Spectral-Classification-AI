{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "This ipynb file generates information for the rest of the document. By importing `astroquery`, after being given a set of ICRS coordinates, the library returns useful information such as its ID, Flux(B), Flux(U), etc,--which will all be saved in `StarList`. The code grabs all information from `Images/(SP_TYPE).txt`, which totals to 7000 random stars generated by simbad through `sptype`. Using the flux values, the code compares the calculated flux with the given flux by using BV_index, UB_index, and so on, outputting a percentage of each score and graphed using bar and pie in `matplotlib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pip install the following libraries (will be used for coordinate conversion, astronomy data, plotting, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install the following libraries:\n",
    "import numpy as np \n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "#pip install pandas\n",
    "import pandas as pd\n",
    "#Create Info-table based on available data\n",
    "#pip install astroquery\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "IMGDATASET_PATH, folder_path, count_path = os.path.join('Dataset', 'Dataset.csv'), os.path.join('Images'), 'Count.csv' #Sets up path to specific items using os.path.join for usage on both Linux and Windows\n",
    "A, B, F, G, K, M, O = 'A', 'B', 'F', 'G', 'K', 'M', 'O' #Sets up the Spectral Types\n",
    "\n",
    "COUNT_PATH = os.path.join(folder_path, count_path) #Sets up path to Count.csv using os.path.join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating the CSV File with the total counts in Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_csv():\n",
    "    Count = pd.read_csv(COUNT_PATH, index_col=0) #Reads CSV file and loads with pandas -> path set above\n",
    "    DSet = pd.read_csv(IMGDATASET_PATH, index_col=0)\n",
    "\n",
    "    for class_dir in (A, B, F, G, K, M, O):\n",
    "        num_items = len(DSet[DSet['Spectral Class'] == class_dir]) #Checks the number of files in the Dataset class folders, lists these as the number of items in each class. \n",
    "\n",
    "        Count[class_dir][0] = num_items #Updates the pandas Dataframe to reflect the updated number of files in the Dataset\n",
    "\n",
    "    Count.to_csv(COUNT_PATH) #Saves dataset\n",
    "\n",
    "update_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Data Completion\n",
    "This codes write to `GeneratedData.txt` for every 7000 stars and for every star contains their numerical number and [\"ID\",\"Spectral Class\",\"Ra\",\"Dec\",\"flux(U)\",\"flux(B)\",\"flux(V)\", \"flux(R)\", \"flux(I)\",\"flux(G)\",\"flux(J)\",\"flux(H)\",\"flux(K)\"]. The function `parse` takes a raw coordinate from a spectral type txt under images and adds the colon inside to pass it on to `get_simbad_data`. That function takes the coordinate and spectral type and converts to pass on to `astoquery` which returns a `result_table`. From that, we use indices to obtain all necessary information which we add to `StarList`. Then it writes all 7000 stars to the `GeneratedData.txt`. On initial runthrough, there will be no cache and therefore the code will run quicker with subsequent executions with initial commit 7000 stars and more than a second for each star with subsequent executions being almost instantaneous. There are no other ways to speed up this code. **PLEASE DO NOT RUN THE BELOW CODE, AS IT WILL TAKE A WHILE TO DOWNLOAD THE INFORMATION FOR 7000 STARS AND SHUFFLE THE DATASET.** Furthermore, if you do run this, this will fail multiple times due to Simbad timing people out after a number of internet requests over a short period of time. If this happens, just rerun the cell below. Simbad will cache data, so it should run much faster. If you don't want to wait, you can get GeneratedData.txt and place it in the Images folder from the ZIP file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_response = False \n",
    "while not valid_response:\n",
    "    response = input('Do you really want to run this block of code? This will BREAK THE IMAGE DATASET (IRREPAIRABLE), AND YOU WILL NEED TO MANUALLY RECREATE THE IMAGE DATASET USING Image Dataset.ipynb BECAUSE IT IS SPECIFICALLY SET UP FOR SHUFFLING!!! Enter (y/n) for yes/no')\n",
    "\n",
    "    if response.lower() == 'y':\n",
    "        f = open(os.path.join('Images', 'GeneratedData.txt'), \"w\")\n",
    "        StarList=[[\"ID\",\"Spectral Class\",\"Ra\",\"Dec\",\"flux(U)\",\"flux(B)\",\"flux(V)\", \"flux(R)\", \"flux(I)\",\"flux(G)\",\"flux(J)\",\"flux(H)\",\"flux(K)\"]]\n",
    "        #StarList would be eventually appended to contain all (7000) of the stars\n",
    "        Count=0\n",
    "\n",
    "        def parse(coord):\n",
    "            for i,s in enumerate(coord):\n",
    "                if s == '+' or s=='-':\n",
    "                    return \":\".join(coord[:i].split())+\" \"+\":\".join(coord[i:].split()) #Adding colons in between the ICRS coordinate, instead of spaces\n",
    "\n",
    "        def get_simbad_data(sp, cmd):\n",
    "            global Count\n",
    "            Count+=1\n",
    "            StarList.append([])\n",
    "            # Convert coordinates to astropy SkyCoord object\n",
    "            # cmd: Right Ascension and Declination in the format \"h:m:s +d:m:s\".\n",
    "            #separate into ra and dec\n",
    "            ra, dec=cmd.split()\n",
    "            ra = coord.Angle(ra, unit=u.hourangle)\n",
    "            dec = coord.Angle(dec, unit=u.deg)\n",
    "            coords = coord.SkyCoord(ra, dec, frame='icrs') #Setting up the specific coordinates for the star\n",
    "            \n",
    "            # Set up Simbad instance, timeout if needed\n",
    "            custom_simbad = Simbad()\n",
    "            custom_simbad.add_votable_fields(\"flux(U)\",\"flux(B)\",\"flux(V)\", \"flux(R)\", \"flux(I)\",\"flux(G)\",\"flux(J)\",\"flux(H)\",\"flux(K)\")\n",
    "            result_table = custom_simbad.query_region(coords)  # Change radius if needed\n",
    "            # print(result_table)\n",
    "\n",
    "            #FOR EACH OF THE TRY, EXCEPTS, -- represents when the data is NOT PRESENT\n",
    "            try: \n",
    "                StarList[Count].append(str(result_table[0][0]))\n",
    "            except:\n",
    "                StarList[Count].append(\"--\") \n",
    "            try: \n",
    "                StarList[Count].append(sp)\n",
    "            except:\n",
    "                StarList[Count].append(\"--\")\n",
    "            try: \n",
    "                StarList[Count].append(str(result_table[0][1]))\n",
    "            except:\n",
    "                StarList[Count].append(\"--\")\n",
    "            try:\n",
    "                StarList[Count].append(str(result_table[0][2]))\n",
    "            except:\n",
    "                StarList[Count].append(\"--\")\n",
    "            for i in range(11,20):\n",
    "                try: \n",
    "                    StarList[Count].append(str(result_table[0][i]))\n",
    "                except:\n",
    "                    StarList[Count].append(\"--\")\n",
    "\n",
    "\n",
    "        Stars=[\"O\",\"B\",\"A\",\"F\",\"G\",\"K\",\"M\"]\n",
    "\n",
    "        count=0\n",
    "\n",
    "        # get_simbad_data(\"O\", \"02:22:54.2923 +41:28:47.724\")\n",
    "\n",
    "        for Star in Stars:\n",
    "            with open(os.path.join('Images', Star+'.txt'), \"r\") as file:\n",
    "                # Read and process each line one by one\n",
    "                for i in range(9):\n",
    "                    file.readline()\n",
    "                for line in file:\n",
    "                    count+=1\n",
    "                    print(count)\n",
    "                    # Process the current line (run function above)\n",
    "                    get_simbad_data(Star,parse(line.split(\"|\")[3]))\n",
    "                    # get_simbad_data(str(line.strip()))\n",
    "                file.close()\n",
    "\n",
    "        Star = pd.DataFrame(StarList) #Turns into Pandas DataFrame for easier saving to txt file\n",
    "        Star.columns = Star.iloc[0] #Sets the columns of the Pandas Dataframe as first row of the StarList -> this is because StarList was set up that way\n",
    "        Star = Star[1:] #Removes the first row from the data of the Pandas DataFrame because it is now the column names\n",
    "        Star.to_csv(os.path.join('Images', 'GeneratedData.txt'), sep=',') #Saves to CSV with os.path.join for Linux AND Windows compatibility\n",
    "        valid_response = True\n",
    "    \n",
    "    elif response.lower() == 'n':\n",
    "        valid_response = True \n",
    "    \n",
    "    else:\n",
    "        print('Enter \"y\" or \"n\" so that the code can know your intentions!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "There are two types of graphs. The first graph is paramerized by bound, which takes the type of color index, indices of the flux, and stellar classification parameters. The numbers are defined by taking the average between bridges of __[Intrinsic colours as a function of spectral type](https://www.stsci.edu/~inr/intrins.html)__ (click for link). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exexcute only if GeneratedData.txt is valid, returns distribution\n",
    "StarList = pd.read_csv(os.path.join('Images', 'GeneratedData.txt'), index_col=0).to_numpy() #Takes StarList from the GeneratedData.txt\n",
    "\n",
    "Ans=[]\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(14, 4), layout=\"constrained\") #Sets up subplots\n",
    "axes = axes.flatten() #Flattens axes for easier access\n",
    "p=-1\n",
    "def bound(s,ind1, ind2, a,b,c,d,e,f):\n",
    "    global p\n",
    "    count=7000\n",
    "    ac=0\n",
    "    t=[]\n",
    "    for i,Star in enumerate(StarList): #Evaluates using types of manual spectral classification for all star in StarList\n",
    "        # if i!=0 and Star[1]!='---':\n",
    "        try:\n",
    "            BV = float(Star[ind1])-float(Star[ind2])\n",
    "            if BV < a: spec = \"O\"\n",
    "            elif a <= BV < b: spec = \"B\"\n",
    "            elif b <= BV < c: spec = \"A\"\n",
    "            elif c <= BV < d: spec = \"F\"\n",
    "            elif d <= BV < e: spec = \"G\"\n",
    "            elif e <= BV < f: spec = \"K\"\n",
    "            elif BV >= f : spec = \"M\"\n",
    "            else: spec = \"N/A\"\n",
    "        except:\n",
    "            spec=\"N/A\"\n",
    "        t.append(spec)\n",
    "        if spec==Star[1]: ac+=1\n",
    "    Ans.append(t)\n",
    "    p+=1\n",
    "    axes[p].pie([count-ac,ac], labels=[\"Incorrect\", \"Correct\"], colors=[\"Silver\",\"Royalblue\"], explode=(0,0.06), autopct='%1.1f%%', startangle=90, shadow=True)\n",
    "    axes[p].set_title('Accuracy of '+s+'-Calulated Spectral Classification')\n",
    "    axes[p].axis('equal')\n",
    "\n",
    "bound(\"BV\", 5,6,-0.30,-0.025,0.31,0.565,0.775,1.35)\n",
    "bound(\"UB\", 4,5,-1.08,-0.06,0.055,0.04,0.37,1.22)\n",
    "bound(\"VJ\", 6,10,-0.80,-0.19,0.34,0.83,1.24,2.395)\n",
    "bound(\"VH\", 6,11,-0.92,-0.24,0.53,1.105,1.555,1.455)\n",
    "bound(\"VK\", 6,12,-0.97,-0.215,0.48,1.085,1.605,3.15)\n",
    "fig.delaxes(axes[5])\n",
    "plt.show()\n",
    "\n",
    "def most_frequent(List):\n",
    "    counter = 0\n",
    "    num = List[0]\n",
    "     \n",
    "    for i in List:\n",
    "        curr_frequency = List.count(i)\n",
    "        if(curr_frequency> counter):\n",
    "            counter = curr_frequency\n",
    "            num = i\n",
    " \n",
    "    return num\n",
    "\n",
    "\n",
    "L=['O','B','A','F','G','K','M']\n",
    "\n",
    "correct=0\n",
    "correct2=0\n",
    "inv=0\n",
    "Ans2=[]\n",
    "for i in range(7000):\n",
    "    temp=[]\n",
    "    counter=0\n",
    "    for k in range(5):\n",
    "        temp.append(Ans[k][i])\n",
    "        if Ans[k][i]==\"N/A\": counter+=1\n",
    "    if StarList[i][1]==most_frequent(temp):\n",
    "        correct+=1\n",
    "    Ans2.append(most_frequent(temp))\n",
    "    for k in range(5):\n",
    "        if Ans[k][i]==StarList[i][1]:\n",
    "            correct2+=1\n",
    "            break\n",
    "    if counter==5: inv+=1\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 4), layout=\"constrained\")\n",
    "axes = axes.flatten()\n",
    "axes[0].pie([7000-correct-inv, correct], labels=[\"Incorrect\", \"Correct\"], colors=[\"Silver\",\"Royalblue\"], explode=(0,0.06), autopct='%1.1f%%', startangle=90, shadow=True)\n",
    "axes[0].set_title('Accuracy of Total-Calulated Spectral Classification')\n",
    "axes[0].axis('equal')\n",
    "axes[1].pie([7000-correct2-inv, correct2], labels=[\"Incorrect\", \"MergeCorrect\"], colors=[\"Silver\",\"Royalblue\"], explode=(0,0.06), autopct='%1.1f%%', startangle=90, shadow=True)\n",
    "axes[1].set_title('Accuracy of Merged-Calculated Spectral Classification')\n",
    "axes[1].axis('equal')\n",
    "plt.show()\n",
    "plt.pie([inv, correct], labels=[\"Invalid\", \"Correct\"], colors=[\"Silver\",\"Royalblue\"], explode=(0,0.06), autopct='%1.1f%%', startangle=90, shadow=True)\n",
    "plt.show()\n",
    "\n",
    "print(len(Ans2))\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 9), layout=\"constrained\")\n",
    "axes = axes.flatten()\n",
    "plt.title(\"Steller Classification Evaluation\")\n",
    "nums=[]\n",
    "for k in range(7):\n",
    "    prediction=[0,0,0,0,0,0,0]\n",
    "    colors=[\"Silver\",\"Silver\",\"Silver\",\"Silver\",\"Silver\",\"Silver\",\"Silver\"]\n",
    "    colors[k]=\"RoyalBlue\"\n",
    "    for i in range(1001):\n",
    "        try: prediction[L.index(Ans2[k*1000+i])]+=1\n",
    "        except: pass\n",
    "    axes[k].bar(L,prediction,color=colors)\n",
    "    axes[k].set_title(L[k])\n",
    "    nums.append(prediction[k])\n",
    "fig.delaxes(axes[7])\n",
    "fig.delaxes(axes[8])\n",
    "plt.show()\n",
    "\n",
    "def linear(x, m, b):\n",
    "    return m * x + b\n",
    "\n",
    "xs=[1,2,3,4,5,6,7]\n",
    "# Perform the curve fit\n",
    "params, covariance = curve_fit(linear, xs[2:], nums[2:])\n",
    "m_fit, b_fit = params\n",
    "# Generate the fitted curve\n",
    "x_fit = np.linspace(min(xs), max(xs), 100)\n",
    "y_fit = linear(x_fit, m_fit, b_fit)\n",
    "# Plot the original data and the fitted curve\n",
    "plt.scatter(xs, nums, label='Data')\n",
    "plt.plot(x_fit, y_fit, label='Fitted Curve', color='red')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Number of Accurate Predictions from O to M')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(m_fit)\n",
    "print(b_fit)\n",
    "residuals = []\n",
    "chi_square=0\n",
    "for i in range(2,7):\n",
    "    temp=nums[i]-linear(xs[i],m_fit,b_fit)\n",
    "    chi_square+=(temp/nums[i])**2\n",
    "print(\"chi_square\",chi_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules Regarding Dataset Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section of code below initializes an empty dataset AND Count.csv for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY RUN THIS MODULE IF YOU WANT TO INITIALIZE AN EMPTY DATASET!!! (But it will check whether it exists also)\n",
    "\n",
    "if not os.path.exists(IMGDATASET_PATH): #Run if a dataset file/folder combo doesn't exist in the user's folder. \n",
    "    \n",
    "    if os.path.exists(os.path.join('Dataset')): #If the folder exists, delete it to remake\n",
    "        os.rmdir(os.path.join('Dataset'))\n",
    "    \n",
    "    os.mkdir(os.path.join('Dataset')) #Make the folder\n",
    "\n",
    "    with open(os.path.join(IMGDATASET_PATH), 'w') as writing: \n",
    "        pass #Make the file \"Dataset.csv\" and write nothing to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY RUN THIS MODULE IF YOU WANT TO INITIALIZE COUNT.CSV IN THE IMAGES FILE!!!! (But it will check whether it exists also)\n",
    "\n",
    "if not os.path.exists(COUNT_PATH): #If Count.csv does not exist\n",
    "\n",
    "    Count_Init = pd.DataFrame(0, index=['Num Items'], columns=(A, B, F, G, K, M, O)) #Initialize DataFrame (Empty, with columns indicating count of items)\n",
    "    Count_Init.to_csv(COUNT_PATH)\n",
    "    \n",
    "    update_csv()\n",
    "\n",
    "    del(Count_Init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(COUNT_PATH) and os.path.exists(IMGDATASET_PATH): #Checks whether path exists and informs user\n",
    "    print('Path Can Be Found')\n",
    "\n",
    "if not os.path.exists(COUNT_PATH): #Informs user that Count.csv does not exist\n",
    "    print('Check whether the Count.csv file exists in the Images folder')\n",
    "\n",
    "if not os.path.exists(IMGDATASET_PATH): #Informs user that Dataset folder/file combo does not exist\n",
    "    print('Check whether the Dataset folder exists.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below SHUFFLES the GeneratedData.txt file because we cannot do that in Model.ipynb for purposes of linking the images with the GeneratedData.txt. **DO NOT RUN THE BELOW CODE, OR IT WILL UNLINK THE SPECIFIC IMAGES WITH THE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHUFFLE THE GENERATEDDATA.TXT FILE (DO NOT RUN!!!)\n",
    "\n",
    "valid_response = False \n",
    "while not valid_response:\n",
    "    response = input('Do you really want to run this block of code? This will BREAK THE IMAGE DATASET (IRREPAIRABLE), AND YOU WILL NEED TO MANUALLY RECREATE THE IMAGE DATASET USING Image Dataset.ipynb BECAUSE IT IS SPECIFICALLY SET UP FOR SHUFFLING!!! Enter (y/n) for yes/no')\n",
    "\n",
    "    if response.lower() == 'y':\n",
    "        shuffled = pd.read_csv(os.path.join('Images', 'GeneratedData.txt'), index_col=0).sample(frac=1).reset_index(drop=True) #Shuffles the DataFrame using sampling and reseting the index\n",
    "        shuffled.to_csv(os.path.join('Images', 'GeneratedData.txt'))\n",
    "        valid_response = True \n",
    "    \n",
    "    elif response.lower() == 'n':\n",
    "        valid_response = True \n",
    "\n",
    "    else: \n",
    "        print('Enter \"y\" or \"n\" so that the code can know your intentions!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cells are for visualization of the dataset specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell if you want to view specifications for the dataset! (Path will NOT be Checked)\n",
    "\n",
    "Count = pd.read_csv(COUNT_PATH, index_col=0)\n",
    "Count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell in addition to the above cell for visualization!\n",
    "figure, ax1 = plt.subplots(1, 1, layout='constrained')\n",
    "\n",
    "ax1.bar(list(Count.columns.values), Count.to_numpy()[0], align='center')\n",
    "ax1.set(title='Number of Images in Dataset', xlabel='Dataset Folder Classification', ylabel='Number of Images')\n",
    "\n",
    "plt.show()\n",
    "print(f'Total Number of Images in Dataset: {sum(Count.to_numpy()[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cells update the dataset and view the GeneratedData.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating the Dataset\n",
    "GEN_PATH = os.path.join(folder_path, 'GeneratedData.txt')\n",
    "\n",
    "GeneratedData = pd.read_csv(GEN_PATH, index_col=0) #Reads Generated Data\n",
    "\n",
    "NewDataset = GeneratedData[['Spectral Class', 'flux(U)', 'flux(B)', 'flux(V)', 'flux(R)', 'flux(I)', 'flux(G)', 'flux(J)', 'flux(K)']].replace('--', 0) #Replaces '--' with 0 (imputation preparation for the model)\n",
    "\n",
    "NewDataset.to_csv(IMGDATASET_PATH) #Saves File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View Pretty Version of TXT file Generated Data\n",
    "GeneratedData.head(len(GeneratedData.index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
